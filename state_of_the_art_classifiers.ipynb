{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named compat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3f7f1ca690bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchi2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/avideep/Films/Important/MSc_Project/pandas.pyc\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_datareader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2010\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avideep/.local/lib/python2.7/site-packages/pandas_datareader/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from .data import (DataReader, Options, get_components_yahoo,\n\u001b[0m\u001b[1;32m      3\u001b[0m                    \u001b[0mget_dailysummary_iex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_enigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_famafrench\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0mget_data_fred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_google\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_moex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mget_data_morningstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_quandl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_stooq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avideep/.local/lib/python2.7/site-packages/pandas_datareader/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_datareader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforex\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAVForexReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_datareader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquotes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAVQuotesReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_datareader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAVSectorPerformanceReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avideep/.local/lib/python2.7/site-packages/pandas_datareader/av/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_datareader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_BaseReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_datareader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRemoteDataError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avideep/.local/lib/python2.7/site-packages/pandas_datareader/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named compat"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from copy import deepcopy\n",
    "from helper_py import load_karypis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 NewsGroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroup_train = fetch_20newsgroups(subset='train')\n",
    "X_train = newsgroup_train.data\n",
    "y_train = newsgroup_train.target\n",
    "newsgroup_test = fetch_20newsgroups(subset='test')\n",
    "X_test = newsgroup_test.data\n",
    "y_test = newsgroup_test.target\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df = 3)\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "features = SelectKBest(chi2, k = 1000)\n",
    "X_train = features.fit_transform(X_train,y_train)\n",
    "X_test = features.transform(X_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_frame(rootdir):\n",
    "    i=0\n",
    "    data_frame = []\n",
    "    data_frame_target = []\n",
    "    target_hash, topic = {}, 0\n",
    "    for root, subFolders, files in os.walk(rootdir):\n",
    "        if(i==0):\n",
    "            subfold = subFolders       \n",
    "        if(i>0):\n",
    "            for filename in files: \n",
    "                fin = open(os.path.join(root,filename), 'r')\n",
    "                data=fin.read().replace('\\n', '')\n",
    "                data_frame.append(data)\n",
    "                if subfold[i-1] not in target_hash:\n",
    "                    target_hash[subfold[i-1]] = topic\n",
    "                    topic += 1\n",
    "                data_frame_target.append(target_hash[subfold[i-1]])\n",
    "                data = \"\"\n",
    "                fin.close()\n",
    "        i=i+1\n",
    "    return data_frame, np.array(data_frame_target,dtype=np.int32)\n",
    "rootdir_train = \"/run/media/avideep/Films/Important/MSc_Project/datasets/Reuters21578-Apte-90Cat/training/\"\n",
    "X_train,y_train = build_data_frame(rootdir_train)\n",
    "rootdir_test = \"/run/media/avideep/Films/Important/MSc_Project/datasets/Reuters21578-Apte-90Cat/test/\"\n",
    "X_test,y_test = build_data_frame(rootdir_test)\n",
    "tfidf = TfidfVectorizer(min_df = 3)\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test_new = []\n",
    "for idx, doc in enumerate(X_test):\n",
    "    try:\n",
    "        tfidf.transform(list(doc))\n",
    "        X_test_new.append(doc)\n",
    "    except UnicodeDecodeError:\n",
    "        pass\n",
    "X_test = tfidf.transform(X_test_new)\n",
    "#X_train = features.fit_transform(X_train,y_train)\n",
    "#X_test = features.transform(X_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(y_test)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "features = SelectKBest(chi2, k = 1000)\n",
    "X_train = features.fit_transform(X_train,y_train)\n",
    "X_test = features.transform(X_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_data_dir = '/run/media/avideep/Films/Important/MSc_Project/datasets/sentiment labelled sentences/amazon_cells_labelled.txt'\n",
    "imdb_data_dir = '/run/media/avideep/Films/Important/MSc_Project/datasets/sentiment labelled sentences/imdb_labelled.txt'\n",
    "yelp_data_dir = '/run/media/avideep/Films/Important/MSc_Project/datasets/sentiment labelled sentences/yelp_labelled.txt'\n",
    "sentiment_data = pd.read_csv(yelp_data_dir,sep='\\t',header=None)\n",
    "X,y = sentiment_data[0].values.tolist(), sentiment_data[1].values.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state =1)\n",
    "#sss = StratifiedShuffleSplit(n_splits=1,test_size=0.20,random_state=1)\n",
    "#train_index, test_index = next(sss.split(X,y))\n",
    "#X_train, X_test = X[train_index], X[test_index]\n",
    "#y_train, y_test = y[train_index], y[test_index]\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Karypis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<138x8261 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 43677 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper_py import load_karypis\n",
    "X,y,z = load_karypis('tr45',path=\"/run/media/avideep/Films/Important/MSc_Project/datasets/karypis\",min_df=3)\n",
    "sss = StratifiedShuffleSplit(n_splits=3,test_size=0.2,random_state=1)\n",
    "train_index, test_index = next(sss.split(X,y))\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "tfidf = TfidfTransformer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X,y = iris.data, iris.target\n",
    "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.20,random_state=1)\n",
    "train_index, test_index = next(sss.split(X,y))\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spambase_data_dir = '/run/media/avideep/Films/Important/MSc_Project/datasets/spambase/spambase.data'\n",
    "spam_data = pd.read_csv(spambase_data_dir,sep=',',header=None)\n",
    "#X,y = spam_data[0].values.tolist(), sentiment_data[1].values.tolist()\n",
    "y = spam_data[57].values.tolist()\n",
    "X = spam_data.drop([57],axis = 1).values.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# breast cancer uci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "iris = load_breast_cancer()\n",
    "X,y = iris.data, iris.target\n",
    "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.20,random_state=1)\n",
    "train_index, test_index = next(sss.split(X,y))\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ecoli UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoli_data_dir = '/run/media/avideep/Films/Important/MSc_Project/datasets/ecoli.data'\n",
    "data = pd.read_csv(ecoli_data_dir,sep=',',header=None)\n",
    "X = np.array(data.drop([0,data.shape[1]-1],axis=1).values.tolist())\n",
    "a = list(np.unique(data.iloc[:,-1]))\n",
    "le = LabelEncoder()\n",
    "le.fit(a)\n",
    "y = le.transform(data.iloc[:,-1].values.tolist())\n",
    "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.20,random_state=1)\n",
    "train_index, test_index = next(sss.split(X,y))\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ionosphere_data_dir = '/run/media/avideep/Films/Important/MSc_Project/datasets/ionosphere.data'\n",
    "data = pd.read_csv(ionosphere_data_dir,sep=',',header=None)\n",
    "X = np.array(data.drop([0,data.shape[1]-1],axis=1).values.tolist())\n",
    "a = list(np.unique(data.iloc[:,-1]))\n",
    "le = LabelEncoder()\n",
    "le.fit(a)\n",
    "y = le.transform(data.iloc[:,-1].values.tolist())\n",
    "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.20,random_state=1)\n",
    "train_index, test_index = next(sss.split(X,y))\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4177, 7)\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "abalone_data_dir = '/run/media/avideep/Films/Important/MSc_Project/datasets/abalone.txt'\n",
    "data = pd.read_csv(abalone_data_dir,sep=',',header=None)\n",
    "X = np.array(data.drop([0,data.shape[1]-1],axis=1).values.tolist())\n",
    "a = list(np.unique(data.iloc[:,-1]))\n",
    "le = LabelEncoder()\n",
    "le.fit(a)\n",
    "y = le.transform(data.iloc[:,-1].values.tolist())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state =1)\n",
    "print(X.shape)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pima India Diabetes Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pid_data_dir = '/run/media/avideep/Films/Important/MSc_Project/datasets/PimaIndiaDiabetes.txt'\n",
    "data = pd.read_csv(pid_data_dir,sep=',',header=None)\n",
    "X = np.array(data.drop([data.shape[1]-1],axis=1).values.tolist())\n",
    "a = list(np.unique(data.iloc[:,-1]))\n",
    "le = LabelEncoder()\n",
    "le.fit(a)\n",
    "y = le.transform(data.iloc[:,-1].values.tolist())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state =1)\n",
    "print(X.shape)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vowel UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 14)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "vowel_data_dir = '/run/media/avideep/Films/Important/MSc_Project/datasets/vowel-context.data'\n",
    "data = pd.read_csv(vowel_data_dir,sep=',',header=None)\n",
    "data_train = data[data[0] == 0]\n",
    "data_test = data[data[0] == 1]\n",
    "X_train = np.array(data_train.drop([0,data.shape[1]-1],axis=1).values.tolist())\n",
    "X_test = np.array(data_test.drop([0,data.shape[1]-1],axis=1).values.tolist())\n",
    "y_train = data_train.iloc[:,-1]\n",
    "y_test = data_test.iloc[:,-1]\n",
    "print(data.shape)\n",
    "print(np.unique(data.iloc[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glass UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 9)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "glass_data_dir = '/run/media/avideep/Films/Important/MSc_Project/datasets/glass.data'\n",
    "data = pd.read_csv(glass_data_dir,sep=',',header=None)\n",
    "X = np.array(data.drop([0,data.shape[1]-1],axis=1).values.tolist())\n",
    "y =np.array(data.iloc[:,-1].values.tolist())\n",
    "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.20,random_state=1)\n",
    "train_index, test_index = next(sss.split(X,y))\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "print(X.shape)\n",
    "print(len(np.unique(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_data_dir = '/run/media/avideep/Films/Important/MSc_Project/datasets/lung-cancer.data'\n",
    "data = pd.read_csv(lung_data_dir,sep=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 54)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "data_dropped = data.drop([4,38],axis = 1)\n",
    "X = np.array(data_dropped.drop([0],axis=1).values.tolist())\n",
    "y = np.array(data_dropped[0].values.tolist())\n",
    "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.20,random_state=1)\n",
    "train_index, test_index = next(sss.split(X,y))\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "print(X.shape)\n",
    "print(len(np.unique(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# satandar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The best grid is as follows: \n",
      "\n",
      "SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Classification of the test samples\n",
      "Evaluation using Precision, Recall and F-measure (micro)\n",
      "\n",
      " Precision:0.927536231884058\n",
      "\n",
      " Recall:0.927536231884058\n",
      "\n",
      " F-measure:0.927536231884058\n",
      "Evaluation using Precision, Recall and F-measure (macro)\n",
      "\n",
      " Precision:0.8530716560128326\n",
      "\n",
      " Recall:0.8541025641025641\n",
      "\n",
      " F-measure:0.8519613582044215\n",
      "\n",
      " Accuracy Score:0.927536231884058\n",
      "CPU times: user 2.19 s, sys: 107 ms, total: 2.29 s\n",
      "Wall time: 1min 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avideep/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/avideep/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svr = SVC(class_weight='balanced')\n",
    "param_grid =[{'kernel':['linear'],'C':[0.01,0.1,1,10,50,100,200]},{'kernel':['rbf'],'C':[0.01,0.1,1,10,50,100,200]},]  # Sets of parameters\n",
    "#param_grid =[{'kernel':['linear'],'C':[1]},]  # Sets of parameters\n",
    "grid = grid_search.GridSearchCV(svr,param_grid,n_jobs=-1, cv=10)          \n",
    "grid.fit(X_train,y_train)    \n",
    "clf= grid.best_estimator_                   # Best grid\n",
    "print ('\\n The best grid is as follows: \\n')\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "print ('Classification of the test samples')\n",
    "predicted_class_label = clf.predict(X_test)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (micro)')\n",
    "pr=precision_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='micro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (macro)')  \n",
    "pr=precision_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='macro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "acc=accuracy_score(y_test, predicted_class_label) \n",
    "print ('\\n Accuracy Score:'+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The best grid is as follows: \n",
      "\n",
      "LogisticRegression(C=10000.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "Classification of the test samples\n",
      "Evaluation using Precision, Recall and F-measure (micro)\n",
      "\n",
      " Precision:0.8823529411764706\n",
      "\n",
      " Recall:0.8823529411764706\n",
      "\n",
      " F-measure:0.8823529411764706\n",
      "Evaluation using Precision, Recall and F-measure (macro)\n",
      "\n",
      " Precision:0.7408424908424908\n",
      "\n",
      " Recall:0.7433905380333953\n",
      "\n",
      " F-measure:0.7354497354497355\n",
      "\n",
      " Accuracy Score:0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(class_weight = 'balanced',penalty = 'l2')\n",
    "param_grid = {'C': [1e6, 1e5, 1e4 , 0.001, 0.01, 0.1, 1] }\n",
    "grid = grid_search.GridSearchCV(logReg,param_grid,n_jobs=4,cv=10)          \n",
    "grid.fit(X_train,y_train)    \n",
    "clf= grid.best_estimator_                   # Best grid\n",
    "print ('\\n The best grid is as follows: \\n')\n",
    "print (grid.best_estimator_ )\n",
    "\n",
    "print ('Classification of the test samples')\n",
    "predicted_class_label = clf.predict(X_test)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (micro)')\n",
    "pr=precision_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='micro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (macro)')  \n",
    "pr=precision_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='macro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "acc=accuracy_score(y_test, predicted_class_label) \n",
    "print ('\\n Accuracy Score:'+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of the test samples\n",
      "Evaluation using Precision, Recall and F-measure (micro)\n",
      "\n",
      " Precision:0.5714285714285714\n",
      "\n",
      " Recall:0.5714285714285714\n",
      "\n",
      " F-measure:0.5714285714285714\n",
      "Evaluation using Precision, Recall and F-measure (macro)\n",
      "\n",
      " Precision:0.38888888888888884\n",
      "\n",
      " Recall:0.6666666666666666\n",
      "\n",
      " F-measure:0.48888888888888893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avideep/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/avideep/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf =  GaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print ('Classification of the test samples')\n",
    "predicted_class_label = clf.predict(X_test)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (micro)')\n",
    "pr=precision_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='micro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (macro)')  \n",
    "pr=precision_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='macro') \n",
    "print ('\\n F-measure:'+str(fm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf =  MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print ('Classification of the test samples')\n",
    "predicted_class_label = clf.predict(X_test)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (micro)')\n",
    "pr=precision_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='micro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (macro)')  \n",
    "pr=precision_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='macro') \n",
    "print ('\\n F-measure:'+str(fm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf =  BernoulliNB()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print ('Classification of the test samples')\n",
    "predicted_class_label = clf.predict(X_test)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (micro)')\n",
    "pr=precision_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='micro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (macro)')  \n",
    "pr=precision_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='macro') \n",
    "print ('\\n F-measure:'+str(fm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of the test samples\n",
      "Evaluation using Precision, Recall and F-measure (micro)\n",
      "\n",
      " Precision:0.5714285714285714\n",
      "\n",
      " Recall:0.5714285714285714\n",
      "\n",
      " F-measure:0.5714285714285714\n",
      "Evaluation using Precision, Recall and F-measure (macro)\n",
      "\n",
      " Precision:0.5555555555555555\n",
      "\n",
      " Recall:0.611111111111111\n",
      "\n",
      " F-measure:0.5666666666666668\n",
      "\n",
      " Accuracy Score:0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = RandomForestClassifier(max_depth=50000, random_state=0,max_features=X_train.shape[1])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print ('Classification of the test samples')\n",
    "predicted_class_label = clf.predict(X_test)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (micro)')\n",
    "pr=precision_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='micro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (macro)')  \n",
    "pr=precision_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='macro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "acc=accuracy_score(y_test, predicted_class_label) \n",
    "print ('\\n Accuracy Score:'+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The best grid is as follows: \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
      "           weights='distance')\n",
      "Classification of the test samples\n",
      "Evaluation using Precision, Recall and F-measure (micro)\n",
      "\n",
      " Precision:0.9057971014492754\n",
      "\n",
      " Recall:0.9057971014492754\n",
      "\n",
      " F-measure:0.9057971014492753\n",
      "Evaluation using Precision, Recall and F-measure (macro)\n",
      "\n",
      " Precision:0.9390146640146639\n",
      "\n",
      " Recall:0.8584134615384615\n",
      "\n",
      " F-measure:0.8785254260752982\n",
      "\n",
      " Accuracy Score:0.9057971014492754\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neigh = KNeighborsClassifier(weights='distance')\n",
    "param_grid = {'n_neighbors' : [i for i in range(2,10)]}\n",
    "grid = grid_search.GridSearchCV(neigh,param_grid,n_jobs=4,cv=10)          \n",
    "grid.fit(X_train,y_train)    \n",
    "clf= grid.best_estimator_                   # Best grid\n",
    "print ('\\n The best grid is as follows: \\n')\n",
    "print (grid.best_estimator_ )\n",
    "\n",
    "print ('Classification of the test samples')\n",
    "predicted_class_label = clf.predict(X_test)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (micro)')\n",
    "pr=precision_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='micro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (macro)')  \n",
    "pr=precision_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='macro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "acc=accuracy_score(y_test, predicted_class_label) \n",
    "print ('\\n Accuracy Score:'+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avideep/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/avideep/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/avideep/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/avideep/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The best grid is as follows: \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "Classification of the test samples\n",
      "Evaluation using Precision, Recall and F-measure (micro)\n",
      "\n",
      " Precision:0.8913043478260869\n",
      "\n",
      " Recall:0.8913043478260869\n",
      "\n",
      " F-measure:0.8913043478260869\n",
      "Evaluation using Precision, Recall and F-measure (macro)\n",
      "\n",
      " Precision:0.8097300031123561\n",
      "\n",
      " Recall:0.7873397435897436\n",
      "\n",
      " F-measure:0.7889943516453524\n",
      "\n",
      " Accuracy Score:0.8913043478260869\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neigh = KNeighborsClassifier(n_jobs=-1)\n",
    "param_grid = {'n_neighbors' : [i for i in range(2,5)]}\n",
    "grid = grid_search.GridSearchCV(neigh,param_grid,n_jobs=-1,cv=10)          \n",
    "grid.fit(X_train,y_train)    \n",
    "clf= grid.best_estimator_                   # Best grid\n",
    "print ('\\n The best grid is as follows: \\n')\n",
    "print (grid.best_estimator_ )\n",
    "\n",
    "print ('Classification of the test samples')\n",
    "predicted_class_label = clf.predict(X_test)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (micro)')\n",
    "pr=precision_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='micro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='micro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "\n",
    "print ('Evaluation using Precision, Recall and F-measure (macro)')  \n",
    "pr=precision_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Precision:'+str(pr))\n",
    "re=recall_score(y_test, predicted_class_label, average='macro')\n",
    "print ('\\n Recall:'+str(re))\n",
    "fm=f1_score(y_test, predicted_class_label, average='macro') \n",
    "print ('\\n F-measure:'+str(fm))\n",
    "acc=accuracy_score(y_test, predicted_class_label) \n",
    "print ('\\n Accuracy Score:'+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
