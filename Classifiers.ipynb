{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from sklearn.datasets import make_moons\n",
    "import csv\n",
    "from sklearn import svm\n",
    "from sklearn import grid_search  \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fread = open('/run/media/avideep/Films/Important/MSc_Project/spambase_data.csv','rb')\n",
    "data = list(csv.reader(fread,delimiter = ','))\n",
    "fread.close()\n",
    "y = [item[57] for item in data]\n",
    "\n",
    "X = data\n",
    "for row in X:\n",
    "    del row[57]   \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The best grid is as follows: \n",
      "\n",
      "SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Classification of the train samples\n",
      "Evaluation using Precision, Recall and F-measure\n",
      "\n",
      " Precision:0.930713057387\n",
      "\n",
      " Recall:0.933617109269\n",
      "\n",
      " F-measure:0.932096343783\n",
      "Classification of the test samples\n",
      "Evaluation using Precision, Recall and F-measure\n",
      "\n",
      " Precision:0.915663073407\n",
      "\n",
      " Recall:0.921136552599\n",
      "\n",
      " F-measure:0.918161959285\n"
     ]
    }
   ],
   "source": [
    "svr = svm.SVC(class_weight='balanced')\n",
    "param_grid =[{'kernel':['linear'],'C':[1,10,100]},{'kernel':['rbf'],'C':[1,10,100]},]  # Sets of parameters\n",
    "grid = grid_search.GridSearchCV(svr,param_grid,n_jobs=4, cv=5)          \n",
    "grid.fit(X_train,y_train)    \n",
    "clf= grid.best_estimator_                   # Best grid\n",
    "print '\\n The best grid is as follows: \\n'\n",
    "print grid.best_estimator_ \n",
    "\n",
    "print 'Classification of the train samples'\n",
    "predicted_class_label = clf.predict(X_train)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print 'Evaluation using Precision, Recall and F-measure'  \n",
    "pr=precision_score(y_train, predicted_class_label, average='macro')\n",
    "print '\\n Precision:'+str(pr)\n",
    "re=recall_score(y_train, predicted_class_label, average='macro')\n",
    "print '\\n Recall:'+str(re)\n",
    "fm=f1_score(y_train, predicted_class_label, average='macro') \n",
    "print '\\n F-measure:'+str(fm)\n",
    "\n",
    "print 'Classification of the test samples'\n",
    "predicted_class_label = clf.predict(X_test)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print 'Evaluation using Precision, Recall and F-measure'  \n",
    "pr=precision_score(y_test, predicted_class_label, average='macro')\n",
    "print '\\n Precision:'+str(pr)\n",
    "re=recall_score(y_test, predicted_class_label, average='macro')\n",
    "print '\\n Recall:'+str(re)\n",
    "fm=f1_score(y_test, predicted_class_label, average='macro') \n",
    "print '\\n F-measure:'+str(fm)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logReg = LogisticRegression(class_weight = 'balanced',penalty = 'l2')\n",
    "param_grid = {'C': [1e6, 1e5, 1e4 , 0.001, 0.01, 0.1, 1] }\n",
    "grid = grid_search.GridSearchCV(logReg,param_grid,n_jobs=4,cv=10)          \n",
    "grid.fit(X_train,y_train)    \n",
    "clf= grid.best_estimator_                   # Best grid\n",
    "print '\\n The best grid is as follows: \\n'\n",
    "print grid.best_estimator_ \n",
    "\n",
    "print 'Classification of the train samples'\n",
    "predicted_class_label = clf.predict(X_train)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print 'Evaluation using Precision, Recall and F-measure'  \n",
    "pr=precision_score(y_train, predicted_class_label, average='micro')\n",
    "print '\\n Precision:'+str(pr)\n",
    "re=recall_score(y_train, predicted_class_label, average='micro')\n",
    "print '\\n Recall:'+str(re)\n",
    "fm=f1_score(y_train, predicted_class_label, average='micro') \n",
    "print '\\n F-measure:'+str(fm)\n",
    "\n",
    "print 'Classification of the test samples'\n",
    "predicted_class_label = clf.predict(X_test)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print 'Evaluation using Precision, Recall and F-measure'  \n",
    "pr=precision_score(y_test, predicted_class_label, average='micro')\n",
    "print '\\n Precision:'+str(pr)\n",
    "re=recall_score(y_test, predicted_class_label, average='micro')\n",
    "print '\\n Recall:'+str(re)\n",
    "fm=f1_score(y_test, predicted_class_label, average='micro') \n",
    "print '\\n F-measure:'+str(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of the test samples\n",
      "Evaluation using Precision, Recall and F-measure\n",
      "\n",
      " Precision:0.815668202765\n",
      "\n",
      " Recall:0.815668202765\n",
      "\n",
      " F-measure:0.815668202765\n"
     ]
    }
   ],
   "source": [
    "#Weighted kNN Classifier :~\n",
    "neigh = KNeighborsClassifier(weights='distance')\n",
    "neigh.fit(X_train,y_train)\n",
    "predicted_class_label_kNN = neigh.predict(X_test)\n",
    "print 'Classification of the test samples'\n",
    "\n",
    "predicted_class_label_kNN = list(predicted_class_label_kNN)\n",
    "\n",
    "print 'Evaluation using Precision, Recall and F-measure'  \n",
    "pr=precision_score(y_test, predicted_class_label_kNN, average='micro')\n",
    "print '\\n Precision:'+str(pr)\n",
    "re=recall_score(y_test, predicted_class_label_kNN, average='micro')\n",
    "print '\\n Recall:'+str(re)\n",
    "fm=f1_score(y_test, predicted_class_label_kNN, average='micro') \n",
    "print '\\n F-measure:'+str(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-51cb4858940b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of the train samples\n",
      "Evaluation using Precision, Recall and F-measure\n",
      "\n",
      " Precision:0.789746917586\n",
      "\n",
      " Recall:0.789746917586\n",
      "\n",
      " F-measure:0.789746917586\n",
      "Classification of the test samples\n",
      "Evaluation using Precision, Recall and F-measure\n",
      "\n",
      " Precision:0.780118499013\n",
      "\n",
      " Recall:0.780118499013\n",
      "\n",
      " F-measure:0.780118499013\n"
     ]
    }
   ],
   "source": [
    "print 'Classification of the train samples'\n",
    "predicted_class_label = clf.predict(X_train)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print 'Evaluation using Precision, Recall and F-measure'  \n",
    "pr=precision_score(y_train, predicted_class_label, average='micro')\n",
    "print '\\n Precision:'+str(pr)\n",
    "re=recall_score(y_train, predicted_class_label, average='micro')\n",
    "print '\\n Recall:'+str(re)\n",
    "fm=f1_score(y_train, predicted_class_label, average='micro') \n",
    "print '\\n F-measure:'+str(fm)\n",
    "\n",
    "print 'Classification of the test samples'\n",
    "predicted_class_label = clf.predict(X_test)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print 'Evaluation using Precision, Recall and F-measure'  \n",
    "pr=precision_score(y_test, predicted_class_label, average='micro')\n",
    "print '\\n Precision:'+str(pr)\n",
    "re=recall_score(y_test, predicted_class_label, average='micro')\n",
    "print '\\n Recall:'+str(re)\n",
    "fm=f1_score(y_test, predicted_class_label, average='micro') \n",
    "print '\\n F-measure:'+str(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of the train samples\n",
      "Evaluation using Precision, Recall and F-measure\n",
      "\n",
      " Precision:0.876054510058\n",
      "\n",
      " Recall:0.876054510058\n",
      "\n",
      " F-measure:0.876054510058\n",
      "Classification of the test samples\n",
      "Evaluation using Precision, Recall and F-measure\n",
      "\n",
      " Precision:0.878867676103\n",
      "\n",
      " Recall:0.878867676103\n",
      "\n",
      " F-measure:0.878867676103\n"
     ]
    }
   ],
   "source": [
    "print 'Classification of the train samples'\n",
    "predicted_class_label = clf.predict(X_train)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print 'Evaluation using Precision, Recall and F-measure'  \n",
    "pr=precision_score(y_train, predicted_class_label, average='micro')\n",
    "print '\\n Precision:'+str(pr)\n",
    "re=recall_score(y_train, predicted_class_label, average='micro')\n",
    "print '\\n Recall:'+str(re)\n",
    "fm=f1_score(y_train, predicted_class_label, average='micro') \n",
    "print '\\n F-measure:'+str(fm)\n",
    "\n",
    "print 'Classification of the test samples'\n",
    "predicted_class_label = clf.predict(X_test)     \n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print 'Evaluation using Precision, Recall and F-measure'  \n",
    "pr=precision_score(y_test, predicted_class_label, average='micro')\n",
    "print '\\n Precision:'+str(pr)\n",
    "re=recall_score(y_test, predicted_class_label, average='micro')\n",
    "print '\\n Recall:'+str(re)\n",
    "fm=f1_score(y_test, predicted_class_label, average='micro') \n",
    "print '\\n F-measure:'+str(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The best grid is as follows: \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=6, p=2,\n",
      "           weights='distance')\n",
      "Classification of the test samples\n",
      "Evaluation using Precision, Recall and F-measure\n",
      "\n",
      " Precision:0.822909809085\n",
      "\n",
      " Recall:0.822909809085\n",
      "\n",
      " F-measure:0.822909809085\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(weights='distance')\n",
    "param_grid = {'n_neighbors' : [i for i in range(4,31)],'n_jobs' : [-1]}\n",
    "grid = grid_search.GridSearchCV(neigh,param_grid,n_jobs=4,cv=10)          \n",
    "grid.fit(X_train,y_train)    \n",
    "clf= grid.best_estimator_                   # Best grid\n",
    "print '\\n The best grid is as follows: \\n'\n",
    "print grid.best_estimator_ \n",
    "predicted_class_label_kNN = clf.predict(X_test)\n",
    "print 'Classification of the test samples'\n",
    "\n",
    "predicted_class_label_kNN = list(predicted_class_label_kNN)\n",
    "\n",
    "print 'Evaluation using Precision, Recall and F-measure'  \n",
    "pr=precision_score(y_test, predicted_class_label_kNN, average='micro')\n",
    "print '\\n Precision:'+str(pr)\n",
    "re=recall_score(y_test, predicted_class_label_kNN, average='micro')\n",
    "print '\\n Recall:'+str(re)\n",
    "fm=f1_score(y_test, predicted_class_label_kNN, average='micro') \n",
    "print '\\n F-measure:'+str(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median computed for class\n",
      "Median computed for class\n",
      "Classification of the test samples\n",
      "Evaluation using Precision, Recall and F-measure\n",
      "\n",
      " Precision:0.601053324556\n",
      "\n",
      " Recall:0.601053324556\n",
      "\n",
      " F-measure:0.601053324556\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from copy import deepcopy\n",
    "\n",
    "fread = open('/run/media/avideep/Films/Important/MSc_Project/spambase_data.csv','rb')\n",
    "data = list(csv.reader(fread,delimiter = ','))\n",
    "fread.close()\n",
    "y = [item[57] for item in data]\n",
    "\n",
    "X = data\n",
    "for row in X:\n",
    "    del row[57]   \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33)\n",
    "class_names = list(np.unique(y_train))\n",
    "class_names_dict = {}\n",
    "for i,val in enumerate(class_names):\n",
    "    class_names_dict[i] = val\n",
    "\n",
    "def findMedians(X_train,y_train):\n",
    "    medians = {}\n",
    "    for class_name in class_names:\n",
    "        class_name_x_train = [X_train[i] for i,val in enumerate(y_train) if val == class_name]\n",
    "        mean = []\n",
    "        for i in range(len(class_name_x_train[1])):\n",
    "            col = []\n",
    "            for row in class_name_x_train:\n",
    "                col.append(row[i])\n",
    "            mean.append(np.mean(np.array(col).astype(np.float)))\n",
    "        median_row = deepcopy(class_name_x_train[0])\n",
    "        for row in class_name_x_train:\n",
    "            if(distance.cosine(np.array(row).astype(np.float),np.array(mean).astype(np.float))>distance.cosine(np.array(median_row).astype(np.float),np.array(mean).astype(np.float))):\n",
    "                median_row = deepcopy(row)\n",
    "        print 'Median computed for class'\n",
    "        medians[class_name] = np.array(median_row).astype(np.float)\n",
    "    return medians\n",
    "\n",
    "def findSelectedSamples(X_train,y_train,x_test,medians):\n",
    "    X_train = np.array(X_train).astype(np.float)\n",
    "    x_test = np.array(x_test).astype(np.float)\n",
    "    x_train_selected = []\n",
    "    y_train_selected = []\n",
    "    for i in range(len(X_train)):\n",
    "        if(distance.cosine(X_train[i],x_test)<=distance.cosine(medians[y_train[i]],x_test)):\n",
    "            x_train_selected.append(X_train[i])\n",
    "            y_train_selected.append(y_train[i])\n",
    "    return np.array(x_train_selected), y_train_selected\n",
    "\n",
    "def sortneighbors(x,y,x_test):\n",
    "    x = np.array(x).astype(np.float)\n",
    "    x_test = np.array(x_test).astype(np.float)\n",
    "    dist = np.empty(len(x))\n",
    "    for i in range(len(x)):\n",
    "        dist[i] = distance.cosine(x[i],x_test)\n",
    "    dist = np.argsort(dist)\n",
    "    x_sorted = np.empty(shape = (len(x),len(X_train[1])))\n",
    "    y_sorted = []\n",
    "    k = 0\n",
    "    for i in dist:\n",
    "        x_sorted[k] = x[i]\n",
    "        y_sorted.append(y[i])\n",
    "        k = k + 1\n",
    "    return x_sorted,y_sorted\n",
    "\n",
    "def cosine_weighted_tkNN(X_train,y_train,x_test,medians):\n",
    "    y_test = '-1'\n",
    "    x_train_selected, y_train_selected = findSelectedSamples(X_train,y_train,x_test,medians) \n",
    "    x_train_sorted, y_train_sorted = sortneighbors(x_train_selected,y_train_selected,x_test)\n",
    "    x_test = np.array(x_test).astype(np.float)  \n",
    "    x_train_sorted = np.array(x_train_sorted).astype(np.float)\n",
    "    L = 2\n",
    "    while(L <= len(x_train_sorted)):\n",
    "        S_L = x_train_sorted[:L]\n",
    "        S_L_y = y_train_sorted[:L]\n",
    "        weights = np.empty(len(S_L))\n",
    "        for i in range(len(S_L)):\n",
    "            weights[i] = distance.cosine(S_L[i],x_test)*distance.cosine(medians[S_L_y[i]],x_test)\n",
    "        class_weights = np.zeros(len(class_names))\n",
    "        p = 0\n",
    "        for class_name in class_names:\n",
    "            class_weights[p] = np.sum([weights[k] for k in np.where(S_L_y == class_name)])\n",
    "            p = p + 1 \n",
    "        max1 = max(class_weights)\n",
    "        class_weights_temp = list(class_weights)\n",
    "        class_weights_temp.remove(max1)\n",
    "        max2 = max(class_weights_temp)\n",
    "        if(max1 - max2 >=0):\n",
    "            y_test = class_names[class_weights_temp.index(max1)]\n",
    "            break\n",
    "        else:\n",
    "            L = L + 1\n",
    "    return y_test\n",
    "medians = findMedians(X_train,y_train)\n",
    "predicted_class_label = list(np.empty(len(X_test)))\n",
    "for i in range(len(X_test)):\n",
    "    predicted_class_label[i] = cosine_weighted_tkNN(X_train,y_train,X_test[i],medians)\n",
    "print 'Classification of the test samples'\n",
    "\n",
    "predicted_class_label = list(predicted_class_label)\n",
    "\n",
    "print 'Evaluation using Precision, Recall and F-measure'  \n",
    "pr=precision_score(y_test, predicted_class_label, average='micro')\n",
    "print '\\n Precision:'+str(pr)\n",
    "re=recall_score(y_test, predicted_class_label, average='micro')\n",
    "print '\\n Recall:'+str(re)\n",
    "fm=f1_score(y_test, predicted_class_label, average='micro') \n",
    "print '\\n F-measure:'+str(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
